{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name InputLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a9cd811db84b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name InputLayer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from utils.data import load_new_data\n",
    "from utils.pass_quality import approx_pq\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, InputLayer, GRU, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nn_model(X_train):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=[X_train.shape[1]]))\n",
    "    model.add(Dense(12, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='MSE',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def rnn_model(X_train):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default classifiers like XGBoost, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for iteration in range(10):\n",
    "    data = load_new_data()\n",
    "    X, y = data[['r.shield', 'r.loop', 'r.shield']].values, data['y'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    xgb = XGBClassifier()\n",
    "    #lr = LogisticRegression()\n",
    "    #nn = nn_model(X_train)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #nn.fit(X_train, y_train, nb_epoch=4, verbose=False)\n",
    "\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    #y_pred_lr = lr.predict(X_test)\n",
    "    #y_pred_nn = (nn.predict(X_test) > 0.5).astype(int).flatten()\n",
    "    errors.append(approx_pq(y_test, y_pred_xgb)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621.40000001"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix(errors).T[1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dim_extend(X, y, n_prev = 3):\n",
    "    \"\"\"\"\"\"\n",
    "    X_ext, y_ext = [], []\n",
    "    \n",
    "    for i in range(len(X) - n_prev + 1):\n",
    "        X_ext.append(np.concatenate([X[i+j] for j in range(n_prev)]))\n",
    "        y_ext.append(y[i + n_prev - 1])\n",
    "        #docY_lab.append(y_lab[i + n_prev -1])\n",
    "    X_ext = np.array(X_ext)\n",
    "    y_ext = np.array(y_ext)\n",
    "    #alsY_lab = np.array(docY_lab)\n",
    "    return X_ext, y_ext#, alsY_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing for  24\n"
     ]
    }
   ],
   "source": [
    "errors_xgb = []\n",
    "\n",
    "for n_prev in range(3, 25):\n",
    "    print \"computing for \", n_prev\n",
    "    clear_output(wait=True)\n",
    "    X_e, y_e = dim_extend(X, y, n_prev)\n",
    "    X_train_e, X_test_e = X_e[:int(len(X_e) * 0.75)], X_e[int(len(X_e) * 0.75):]\n",
    "    y_train_e, y_test_e = y_e[:int(len(y_e) * 0.75)], y_e[int(len(y_e) * 0.75):]\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train_e, y_train_e)\n",
    "    y_pred_e = xgb.predict(X_test_e)\n",
    "    errors_xgb.append(approx_pq(y_test_e, y_pred_e)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769984322484\n",
      "1740.75000001\n",
      "552.136363636\n"
     ]
    }
   ],
   "source": [
    "print (np.mean(np.matrix(errors_xgb).T[0]) + np.max(np.matrix(errors_xgb).T[0])) / 2\n",
    "\n",
    "print (np.mean(np.matrix(errors_xgb).T[1]) + np.max(np.matrix(errors_xgb).T[1])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[1])\n",
    "\n",
    "print (np.mean(np.matrix(errors_xgb).T[2]) + np.max(np.matrix(errors_xgb).T[2])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing for  29\n"
     ]
    }
   ],
   "source": [
    "errors_lr = []\n",
    "\n",
    "for n_prev in range(3, 30):\n",
    "    print \"computing for \", n_prev\n",
    "    clear_output(wait=True)\n",
    "    X_e, y_e = dim_extend(X, y, n_prev)\n",
    "    X_train_e, X_test_e = X_e[:int(len(X_e) * 0.75)], X_e[int(len(X_e) * 0.75):]\n",
    "    y_train_e, y_test_e = y_e[:int(len(y_e) * 0.75)], y_e[int(len(y_e) * 0.75):]\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_e, y_train_e)\n",
    "    y_pred_e = lr.predict(X_test_e)\n",
    "    errors_lr.append(approx_pq(y_test_e, y_pred_e)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791391927479\n",
      "1809.0925926\n",
      "649.37037037\n"
     ]
    }
   ],
   "source": [
    "print (np.mean(np.matrix(errors_lr).T[0]) + np.max(np.matrix(errors_lr).T[0])) / 2\n",
    "\n",
    "print (np.mean(np.matrix(errors_lr).T[1]) + np.max(np.matrix(errors_lr).T[1])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[1])\n",
    "\n",
    "print (np.mean(np.matrix(errors_lr).T[2]) + np.max(np.matrix(errors_lr).T[2])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# nn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing for  24\n"
     ]
    }
   ],
   "source": [
    "errors_nn = []\n",
    "\n",
    "for n_prev in range(20, 25):\n",
    "    print \"computing for \", n_prev\n",
    "    clear_output(wait=True)\n",
    "    X_e, y_e = dim_extend(X, y, n_prev)\n",
    "    X_train_e, X_test_e = X_e[:int(len(X_e) * 0.75)], X_e[int(len(X_e) * 0.75):]\n",
    "    y_train_e, y_test_e = y_e[:int(len(y_e) * 0.75)], y_e[int(len(y_e) * 0.75):]\n",
    "    nn = nn_model(X_train_e)\n",
    "    nn.fit(X_train_e, y_train_e, nb_epoch=int(n_prev / 6.) + 6, verbose=False)\n",
    "    y_pred_e = nn.predict(X_test_e)\n",
    "    errors_nn.append(approx_pq(y_test_e, (nn.predict(X_test_e) > 0.5).astype(int).flatten())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771217306473\n",
      "1742.80000001\n",
      "546.2\n"
     ]
    }
   ],
   "source": [
    "print (np.mean(np.matrix(errors_nn).T[0]) + np.max(np.matrix(errors_nn).T[0])) / 2\n",
    "\n",
    "print (np.mean(np.matrix(errors_nn).T[1]) + np.max(np.matrix(errors_nn).T[1])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[1])\n",
    "\n",
    "print (np.mean(np.matrix(errors_nn).T[2]) + np.max(np.matrix(errors_nn).T[2])) / 2\n",
    "#print np.max(np.matrix(errors_nn).T[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for iteration in range(10):\n",
    "    data = load_new_data()\n",
    "    y_lab, y = data[['r.pass']].values, data['y'].values\n",
    "    _, y = y[:int(len(y_e) * 0.75)], y[int(len(y_e) * 0.75):]\n",
    "    _, y_lab = y_lab[:int(len(y_e) * 0.75)], y_lab[int(len(y_e) * 0.75):]\n",
    "\n",
    "    #xgb = XGBClassifier()\n",
    "    #lr = LogisticRegression()\n",
    "    #nn = nn_model(X_train)\n",
    "\n",
    "    #xgb.fit(X_train, y_train)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #nn.fit(X_train, y_train, nb_epoch=4, verbose=False)\n",
    "\n",
    "    #y_pred_xgb = xgb.predict(X_test)\n",
    "    #y_pred_lr = lr.predict(X_test)\n",
    "    #y_pred_nn = (nn.predict(X_test) > 0.5).astype(int).flatten()\n",
    "    errors.append(approx_pq(y_lab.flatten(), y)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842790279319\n",
      "1730.10000001\n",
      "322.9\n"
     ]
    }
   ],
   "source": [
    "print np.mean(np.matrix(errors).T[0])\n",
    "\n",
    "print np.mean(np.matrix(errors).T[1])\n",
    "#print np.max(np.matrix(errors_nn).T[1])\n",
    "\n",
    "print np.mean(np.matrix(errors).T[2])\n",
    "#print np.max(np.matrix(errors_nn).T[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
